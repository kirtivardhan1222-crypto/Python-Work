{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUqYqoLhyyhqiSfbNvZ4B0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kirtivardhan1222-crypto/Python-Work/blob/main/Python_Code_2nd_Iteration_QA_2nd_Pass.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ClkxIRuAlNu8"
      },
      "outputs": [],
      "source": [
        "# --- INSTALL DEPENDENCY ---\n",
        "!pip install python-docx\n",
        "\n",
        "from docx import Document\n",
        "from google.colab import files\n",
        "import re, textwrap, html\n",
        "from datetime import datetime\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# --- UPLOAD FILE ---\n",
        "print(\"Upload your DOCX file:\")\n",
        "uploaded = files.upload()\n",
        "FILENAME = list(uploaded.keys())[0]\n",
        "print(f\"File uploaded: {FILENAME}\")\n",
        "\n",
        "# --- CONFIGURATION SECTION ---\n",
        "REQUIRED_SECTIONS = [\n",
        "    \"Executive Summary\",\n",
        "    \"Scope\",\n",
        "    \"Findings\",\n",
        "    \"Recommendations\",\n",
        "    \"Conclusion\",\n",
        "]\n",
        "\n",
        "BANNED_WORDS = {\n",
        "    \"utilize\": \"use\",\n",
        "    \"synergy\": \"collaboration\",\n",
        "    \"impactful\": \"effective\",\n",
        "}\n",
        "\n",
        "# --- LOGIC STARTS HERE ---\n",
        "def read_doc(path: str):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      - full_text (str): all paragraph text joined by newlines\n",
        "      - paragraphs (list[str]): raw paragraph strings\n",
        "      - headings_found (set[str]): set of normalized headings detected via Word styles AND text match\n",
        "    \"\"\"\n",
        "    doc = Document(path)\n",
        "    paras = []\n",
        "    headings_found = set()\n",
        "\n",
        "    for p in doc.paragraphs:\n",
        "        txt = p.text or \"\"\n",
        "        paras.append(txt)\n",
        "\n",
        "        # detect headings by Word style (Heading 1/2/3...) OR by text that looks like a section title\n",
        "        style_name = (p.style.name or \"\").lower()\n",
        "        if (\"heading\" in style_name and any(s.lower() in style_name for s in [\"heading\", \"title\"])) or re.match(r\"^\\s*#[#\\s]*\", txt):\n",
        "            headings_found.add(txt.strip().lower())\n",
        "\n",
        "        # also, if a paragraph exactly equals a required section (case-insensitive), count it\n",
        "        if txt.strip().lower() in [s.lower() for s in REQUIRED_SECTIONS]:\n",
        "            headings_found.add(txt.strip().lower())\n",
        "\n",
        "    full_text = \"\\n\".join(paras)\n",
        "    return full_text, paras, headings_found\n",
        "\n",
        "def normalize(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s.strip().lower())\n",
        "\n",
        "def check_required_sections(full_text: str, headings_found: set) -> dict:\n",
        "    \"\"\"\n",
        "    Checks sections both by keyword presence in text AND by headings_found.\n",
        "    \"\"\"\n",
        "    tlow = full_text.lower()\n",
        "    results = {}\n",
        "    for sec in REQUIRED_SECTIONS:\n",
        "        present = (sec.lower() in tlow) or (sec.lower() in headings_found)\n",
        "        results[sec] = present\n",
        "    return results\n",
        "\n",
        "def check_banned_words(full_text: str) -> dict:\n",
        "    \"\"\"\n",
        "    Returns dict: bad_word -> list of (start,end) indices where found\n",
        "    \"\"\"\n",
        "    tlow = full_text.lower()\n",
        "    hits = {}\n",
        "    for bad in BANNED_WORDS.keys():\n",
        "        pattern = rf\"\\b{re.escape(bad.lower())}\\b\"\n",
        "        matches = list(re.finditer(pattern, tlow))\n",
        "        if matches:\n",
        "            hits[bad] = [(m.start(), m.end()) for m in matches]\n",
        "    return hits\n",
        "\n",
        "def check_duplicates(paragraphs: list[str]) -> list[str]:\n",
        "    \"\"\"\n",
        "    Returns list of duplicate lines (exact text matches after stripping)\n",
        "    \"\"\"\n",
        "    lines = [l.strip() for l in paragraphs if l.strip()]\n",
        "    seen = set()\n",
        "    dups = []\n",
        "    for l in lines:\n",
        "        if l in seen:\n",
        "            dups.append(l)\n",
        "        else:\n",
        "            seen.add(l)\n",
        "    return dups\n",
        "\n",
        "def quality_score(section_ok: dict, banned_hits: dict, dup_lines: list[str]) -> int:\n",
        "    \"\"\"\n",
        "    Simple score out of 100:\n",
        "      - Start at 100\n",
        "      - -10 for each missing required section (min 0)\n",
        "      - -2 for each banned word occurrence instance\n",
        "      - -3 for each duplicate line (capped to 30)\n",
        "      - Clamp 0..100\n",
        "    \"\"\"\n",
        "    score = 100\n",
        "    missing = sum(1 for v in section_ok.values() if not v)\n",
        "    banned_count = sum(len(v) for v in banned_hits.values())\n",
        "    dup_count = len(dup_lines)\n",
        "\n",
        "    score -= 10 * missing\n",
        "    score -= 2 * banned_count\n",
        "    score -= min(30, 3 * dup_count)\n",
        "    return max(0, min(100, score))\n",
        "\n",
        "def highlight_banned_in_html(text: str, banned_hits: dict) -> str:\n",
        "    \"\"\"\n",
        "    Produces HTML with banned words wrapped in <mark>.\n",
        "    \"\"\"\n",
        "    # Build segments without overlapping replacements by walking the string\n",
        "    marks = []\n",
        "    for bad, ranges in banned_hits.items():\n",
        "        for (s, e) in ranges:\n",
        "            marks.append((s, e, bad))\n",
        "    marks.sort(key=lambda x: x[0])\n",
        "\n",
        "    out = []\n",
        "    cursor = 0\n",
        "    safe = html.escape(text)\n",
        "    # BUT indices were on lowercased original; we need to rebuild mapping\n",
        "    # Simple approach: rebuild by scanning original text (not escaped), then escape on the fly.\n",
        "    # Redo with original text:\n",
        "    raw = text\n",
        "    out = []\n",
        "    cursor = 0\n",
        "    # Rebuild ranges on raw (already are). We will slice raw, then escape each slice.\n",
        "    for (s, e, bad) in marks:\n",
        "        if s < cursor:\n",
        "            continue  # skip overlaps\n",
        "        out.append(html.escape(raw[cursor:s]))\n",
        "        bad_raw = html.escape(raw[s:e])\n",
        "        out.append(f\"<mark title='Use “{BANNED_WORDS[bad]}” instead'>{bad_raw}</mark>\")\n",
        "        cursor = e\n",
        "    out.append(html.escape(raw[cursor:]))\n",
        "    return \"\".join(out)\n",
        "\n",
        "def build_html_report(filename: str,\n",
        "                      section_ok: dict,\n",
        "                      banned_hits: dict,\n",
        "                      dup_lines: list[str],\n",
        "                      highlighted_text_html: str,\n",
        "                      score: int) -> str:\n",
        "    now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    missing_list = [sec for sec, ok in section_ok.items() if not ok]\n",
        "\n",
        "    css = \"\"\"\n",
        "    <style>\n",
        "      body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; line-height: 1.5; padding: 24px; }\n",
        "      h1 { margin-bottom: 0; }\n",
        "      .meta { color: #555; margin-bottom: 20px; }\n",
        "      .chip { display: inline-block; padding: 4px 10px; border-radius: 16px; border: 1px solid #ddd; margin: 2px 6px 2px 0; }\n",
        "      .ok { background: #e9f7ef; border-color: #b2dfbd; }\n",
        "      .bad { background: #fdecea; border-color: #f5c6cb; }\n",
        "      mark { padding: 0 3px; border-radius: 3px; }\n",
        "      .score { font-size: 28px; font-weight: 700; }\n",
        "      .sec { margin-top: 24px; }\n",
        "      pre { white-space: pre-wrap; word-wrap: break-word; border: 1px solid #eee; padding: 12px; border-radius: 6px; background: #fafafa; }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "    sec_html = \"\".join(\n",
        "        f\"<span class='chip {'ok' if ok else 'bad'}'>{html.escape(sec)}: {'Present' if ok else 'Missing'}</span>\"\n",
        "        for sec, ok in section_ok.items()\n",
        "    )\n",
        "\n",
        "    banned_html = \"✅ No banned words found.\" if not banned_hits else \"<br>\".join(\n",
        "        f\"⚠️ <b>{html.escape(bad)}</b> → “{html.escape(BANNED_WORDS[bad])}” ({len(ranges)}×)\"\n",
        "        for bad, ranges in banned_hits.items()\n",
        "    )\n",
        "\n",
        "    dups_html = \"✅ No duplicate lines found.\" if not dup_lines else \"<ul>\" + \"\".join(\n",
        "        f\"<li>{html.escape(l[:120])}{'…' if len(l)>120 else ''}</li>\" for l in dup_lines\n",
        "    ) + \"</ul>\"\n",
        "\n",
        "    html_doc = f\"\"\"<!doctype html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\">\n",
        "<title>Report Audit — {html.escape(filename)}</title>\n",
        "{css}\n",
        "</head>\n",
        "<body>\n",
        "  <h1>Report Audit</h1>\n",
        "  <div class=\"meta\">{html.escape(filename)} • Generated {html.escape(now)}</div>\n",
        "\n",
        "  <div class=\"sec\">\n",
        "    <div class=\"score\">Quality Score: {score}/100</div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"sec\">\n",
        "    <h2>Required Sections</h2>\n",
        "    {sec_html}\n",
        "  </div>\n",
        "\n",
        "  <div class=\"sec\">\n",
        "    <h2>Banned Words</h2>\n",
        "    <div>{banned_html}</div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"sec\">\n",
        "    <h2>Duplicate Lines</h2>\n",
        "    <div>{dups_html}</div>\n",
        "  </div>\n",
        "\n",
        "  <div class=\"sec\">\n",
        "    <h2>Document (with highlights)</h2>\n",
        "    <pre>{highlighted_text_html}</pre>\n",
        "  </div>\n",
        "</body>\n",
        "</html>\"\"\"\n",
        "    return html_doc\n",
        "\n",
        "# --- RUN ---\n",
        "full_text, paragraphs, headings_found = read_doc(FILENAME)\n",
        "section_ok = check_required_sections(full_text, headings_found)\n",
        "banned_hits = check_banned_words(full_text)\n",
        "dup_lines   = check_duplicates(paragraphs)\n",
        "score       = quality_score(section_ok, banned_hits, dup_lines)\n",
        "\n",
        "highlighted_html = highlight_banned_in_html(full_text, banned_hits)\n",
        "report_html = build_html_report(\n",
        "    filename=FILENAME,\n",
        "    section_ok=section_ok,\n",
        "    banned_hits=banned_hits,\n",
        "    dup_lines=dup_lines,\n",
        "    highlighted_text_html=highlighted_html,\n",
        "    score=score\n",
        ")\n",
        "\n",
        "# Save + display + download\n",
        "out_path = \"report_audit.html\"\n",
        "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(report_html)\n",
        "\n",
        "display(HTML(f\"<p><b>Done.</b> Download the report: <a href='files/{out_path}' target='_blank'>{out_path}</a></p>\"))\n",
        "display(HTML(report_html))\n"
      ]
    }
  ]
}